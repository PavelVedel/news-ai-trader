"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã –∞–∫—Ü–∏–π
"""

import json
import sqlite3
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta, time
from typing import List, Dict, Tuple, Optional
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AnomalyNewsFinder:
    def __init__(self, db_path: str = "data/db/news.db", market_data_path: str = "data/market_data/yahoo/1m"):
        self.db_path = db_path
        self.market_data_path = Path(market_data_path)
        
        # –ß–∞—Å–æ–≤—ã–µ –ø–æ—è—Å–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–µ—Å—Å–∏–π
        self.market_open = time(9, 30)  # 9:30 AM ET
        self.market_close = time(16, 0)  # 4:00 PM ET
        
    def get_all_news_with_symbols(self, limit: int = None) -> List[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å –∏—Ö —Å–∏–º–≤–æ–ª–∞–º–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            
            cursor = conn.cursor()
            if limit:
                cursor.execute("""
                    SELECT news_id, created_at_utc, symbols_json, headline, source
                    FROM news_raw
                    ORDER BY created_at_utc DESC
                    LIMIT ?
                """, (limit,))
            else:
                cursor.execute("""
                    SELECT news_id, created_at_utc, symbols_json, headline, source
                    FROM news_raw
                    ORDER BY created_at_utc
                """)
            
            news_list = []
            for row in cursor.fetchall():
                try:
                    symbols = json.loads(row['symbols_json'])
                    if isinstance(symbols, list) and symbols:
                        news_list.append({
                            'news_id': row['news_id'],
                            'created_at_utc': row['created_at_utc'],
                            'symbols': symbols,
                            'headline': row['headline'],
                            'source': row['source']
                        })
                except (json.JSONDecodeError, TypeError):
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏ {row['news_id']}")
                    continue
            
            conn.close()
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Å–∏–º–≤–æ–ª–∞–º–∏")
            return news_list
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
            return []
    
    def is_market_open(self, utc_time: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –±—ã–ª –ª–∏ –æ—Ç–∫—Ä—ã—Ç —Ä—ã–Ω–æ–∫ –≤ –º–æ–º–µ–Ω—Ç –≤—ã—Ö–æ–¥–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        try:
            # –ü–∞—Ä—Å–∏–º UTC –≤—Ä–µ–º—è
            dt = datetime.fromisoformat(utc_time.replace('Z', '+00:00'))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ ET (Eastern Time)
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º UTC-5 (EST) –∏–ª–∏ UTC-4 (EDT)
            # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pytz –∏–ª–∏ zoneinfo
            et_time = dt - timedelta(hours=5)  # UTC-5
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å (–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫-–ø—è—Ç–Ω–∏—Ü–∞)
            if et_time.weekday() >= 5:  # 5=—Å—É–±–±–æ—Ç–∞, 6=–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
            current_time = et_time.time()
            
            # –†–∞—Å—à–∏—Ä—è–µ–º —Ç–æ—Ä–≥–æ–≤—ã–µ —á–∞—Å—ã –¥–ª—è —É—á–µ—Ç–∞ –ø—Ä–µ-–º–∞—Ä–∫–µ—Ç–∞ –∏ –ø–æ—Å–ª–µ-–º–∞—Ä–∫–µ—Ç–∞
            # Pre-market: 4:00 AM - 9:30 AM ET
            # Regular hours: 9:30 AM - 4:00 PM ET  
            # After-hours: 4:00 PM - 8:00 PM ET
            pre_market_start = time(4, 0)
            after_market_end = time(20, 0)
            
            return (pre_market_start <= current_time <= after_market_end)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏: {e}")
            return False
    
    def get_market_session_info(self, utc_time: str) -> Tuple[bool, str]:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ä—ã–Ω–∫–∞ –∏ —Ç–∏–ø —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏"""
        try:
            # –ü–∞—Ä—Å–∏–º UTC –≤—Ä–µ–º—è
            dt = datetime.fromisoformat(utc_time.replace('Z', '+00:00'))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ ET (Eastern Time)
            et_time = dt - timedelta(hours=5)  # UTC-5
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å (–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫-–ø—è—Ç–Ω–∏—Ü–∞)
            if et_time.weekday() >= 5:  # 5=—Å—É–±–±–æ—Ç–∞, 6=–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
                return False, "weekend"
            
            current_time = et_time.time()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
            if time(4, 0) <= current_time < time(9, 30):
                return True, "pre_market"
            elif time(9, 30) <= current_time <= time(16, 0):
                return True, "regular_hours"
            elif time(16, 0) < current_time <= time(20, 0):
                return True, "after_hours"
            else:
                return False, "closed"
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏: {e}")
            return False, "unknown"
    
    def get_candles_for_symbol_date(self, symbol: str, date_str: str) -> Optional[pd.DataFrame]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–µ—á–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            symbol_path = self.market_data_path / symbol
            if not symbol_path.exists():
                return None
            
            file_path = symbol_path / f"{date_str}.parquet"
            if not file_path.exists():
                return None
            
            # –ß–∏—Ç–∞–µ–º parquet —Ñ–∞–π–ª
            df = pd.read_parquet(file_path)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
            if 'timestamp' not in df.columns and df.index.name == 'timestamp':
                df = df.reset_index()
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤ datetime –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if 'timestamp' in df.columns:
                if df['timestamp'].dtype == 'object':
                    df['timestamp'] = pd.to_datetime(df['timestamp'])
                df = df.set_index('timestamp')
            
            return df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å–≤–µ—á–µ–π –¥–ª—è {symbol} –Ω–∞ {date_str}: {e}")
            return None

    @staticmethod
    def _typical_price(df: pd.DataFrame) -> pd.Series:
        """–¢–∏–ø–∏—á–Ω–∞—è —Ü–µ–Ω–∞ —Å–≤–µ—á–∏: (H+L+C)/3. –¢—Ä–µ–±—É—é—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∏ high, low, close."""
        if not {'high', 'low', 'close'}.issubset(df.columns):
            raise ValueError("–û–∂–∏–¥–∞—é—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∏: high, low, close")
        tp = (df['high'] + df['low'] + df['close']) / 3.0
        tp.name = 'typical_price'
        return tp

    @staticmethod
    def _price_at_or_before(series: pd.Series, t: datetime) -> Optional[float]:
        """–¶–µ–Ω–∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–µ –Ω–µ –ø–æ–∑–∂–µ t (<= t)."""
        s = series.loc[series.index <= pd.Timestamp(t)]
        return None if s.empty else float(s.iloc[-1])

    @staticmethod
    def _price_at_or_after(series: pd.Series, t: datetime) -> Optional[float]:
        """–¶–µ–Ω–∞ –Ω–∞ –ø–µ—Ä–≤–æ–π —Å–≤–µ—á–µ –Ω–µ —Ä–∞–Ω—å—à–µ t (>= t)."""
        s = series.loc[series.index >= pd.Timestamp(t)]
        return None if s.empty else float(s.iloc[0])

    @staticmethod
    def _log_returns(series: pd.Series) -> pd.Series:
        """–õ–æ–≥-–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ü–µ–Ω."""
        return np.log(series).diff()

    @staticmethod
    def _cum_change_pct(p_start: Optional[float], p_end: Optional[float]) -> Optional[float]:
        """–ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (–∏–∑ –ª–æ–≥-—Ñ–æ—Ä–º—ã) –º–µ–∂–¥—É –¥–≤—É–º—è —Ü–µ–Ω–∞–º–∏."""
        if p_start is None or p_end is None or p_start <= 0 or p_end <= 0:
            return None
        return float((np.exp(np.log(p_end) - np.log(p_start)) - 1.0) * 100.0)

    @staticmethod
    def _realized_vol_pct(log_ret: pd.Series) -> Optional[float]:
        """–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –æ–∫–Ω–µ: sqrt(sum r_t^2), –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö."""
        if log_ret.empty:
            return None
        return float(np.sqrt((log_ret ** 2).sum()) * 100.0)

    def find_price_changes(self, symbol: str, news_time: str, candles_df: pd.DataFrame) -> Optional[Dict]:
        """–ù–∞–π—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã –≤–æ–∫—Ä—É–≥ –Ω–æ–≤–æ—Å—Ç–∏ + –¥–æ–±–∞–≤–∏—Ç—å pre/post CAR –∏ RV –±–µ–∑ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤."""
        try:
            news_dt = datetime.fromisoformat(news_time.replace('Z', '+00:00')).replace(tzinfo=None)

            # –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞–Ω–Ω—ã—Ö
            data_start = candles_df.index.min().replace(tzinfo=None)
            data_end = candles_df.index.max().replace(tzinfo=None)

            # –¢–∏–ø–∏—á–Ω–∞—è —Ü–µ–Ω–∞ –Ω–∞ –≤—Å–µ—Ö —Å–≤–µ—á–∞—Ö –¥–Ω—è
            tp = self._typical_price(candles_df)
            log_r = self._log_returns(tp)

            # --- —Ä–∞—Å—á–µ—Ç –±–∞–∑–æ–≤–æ–≥–æ 3-—á–∞—Å–æ–≤–æ–≥–æ –æ–∫–Ω–∞ –ø–æ—Å–ª–µ –Ω–æ–≤–æ—Å—Ç–∏ (–∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ) ---
            if news_dt > data_end:
                start_time = data_end - timedelta(hours=3)
                end_time = data_end
                logger.info("–ù–æ–≤–æ—Å—Ç—å –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã—Ç–∏—è —Ä—ã–Ω–∫–∞, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —á–∞—Å–∞ –¥–∞–Ω–Ω—ã—Ö")
            else:
                start_time = news_dt
                end_time = news_dt + timedelta(hours=3)

            start_time_pd = pd.Timestamp(start_time)
            end_time_pd = pd.Timestamp(end_time)

            mask_3h = (candles_df.index >= start_time_pd) & (candles_df.index <= end_time_pd)
            relevant_candles = candles_df[mask_3h]

            if relevant_candles.empty:
                return None

            # –¶–µ–Ω–∞ –≤ –º–æ–º–µ–Ω—Ç –Ω–æ–≤–æ—Å—Ç–∏ (–±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å–≤–µ—á—É >= news_dt, —Ç–∏–ø–∏—á–Ω–∞—è —Ü–µ–Ω–∞)
            price_at_news = self._price_at_or_after(tp, news_dt)
            if price_at_news is None:
                # fallback: –µ—Å–ª–∏ –Ω–µ—Ç —Å–≤–µ—á–µ–π –ø–æ—Å–ª–µ, –≤–æ–∑—å–º–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–µ—Ä–µ–¥ —Å–æ–±—ã—Ç–∏–µ–º
                price_at_news = self._price_at_or_before(tp, news_dt)
            if price_at_news is None:
                return None

            # --- –°—Ç–∞—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å) ---
            max_high = relevant_candles['high'].max()
            min_low = relevant_candles['low'].min()
            max_up_pct = ((max_high - price_at_news) / price_at_news) * 100.0
            max_down_pct = ((min_low - price_at_news) / price_at_news) * 100.0
            max_movement_pct = max(abs(max_up_pct), abs(max_down_pct))
            is_anomaly = max_movement_pct >= 0.5
            if abs(max_up_pct) > abs(max_down_pct):
                movement_direction = "up"
                movement_pct = max_up_pct
            else:
                movement_direction = "down"
                movement_pct = max_down_pct

            # --- NEW: –æ–∫–Ω–∞ –¥–ª—è pre/post CAR (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö) ---
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–∫–æ–Ω:
            pre_start = news_dt - timedelta(minutes=60)
            pre_end   = news_dt - timedelta(minutes=5)
            post_15   = news_dt + timedelta(minutes=15)
            post_60   = news_dt + timedelta(minutes=60)
            post_180  = news_dt + timedelta(minutes=180)

            # –¢–æ—á–∫–∏ —Ü–µ–Ω –¥–ª—è –æ–∫–æ–Ω (–∫–æ–Ω—Ü—ã –±–µ—Ä–µ–º "–Ω–µ –ø–æ–∑–∂–µ", –Ω–∞—á–∞–ª–æ pre —Ç–æ–∂–µ "–Ω–µ –ø–æ–∑–∂–µ")
            p_pre_start = self._price_at_or_before(tp, pre_start)
            p_pre_end   = self._price_at_or_before(tp, pre_end)

            p0_post = self._price_at_or_after(tp, news_dt)  # price_at_news —É–∂–µ –ø–æ–¥–æ–±—Ä–∞–Ω –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ
            p_15 = self._price_at_or_before(tp, post_15)
            p_60 = self._price_at_or_before(tp, post_60)
            p_180 = self._price_at_or_before(tp, post_180)

            pre_car_60m_pct = self._cum_change_pct(p_pre_start, p_pre_end)
            post_car_15m_pct = self._cum_change_pct(p0_post, p_15)
            post_car_60m_pct = self._cum_change_pct(p0_post, p_60)
            post_car_180m_pct = self._cum_change_pct(p0_post, p_180)

            # --- NEW: —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –æ–∫–Ω–∞—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ---
            # –ü—Ä–µ–¥–æ–∫–Ω–æ: (pre_start, pre_end]
            pre_mask = (log_r.index > pd.Timestamp(pre_start)) & (log_r.index <= pd.Timestamp(pre_end))
            pre_rv_60m = self._realized_vol_pct(log_r.loc[pre_mask])

            # –ü–æ—Å—Ç–æ–∫–Ω–æ: (news_dt, news_dt+60m]
            post_mask_60 = (log_r.index > pd.Timestamp(news_dt)) & (log_r.index <= pd.Timestamp(post_60))
            post_rv_60m = self._realized_vol_pct(log_r.loc[post_mask_60])

            return {
                'symbol': symbol,
                'price_at_news': float(price_at_news),
                'max_high': float(max_high),
                'min_low': float(min_low),
                'max_up_pct': float(max_up_pct),
                'max_down_pct': float(max_down_pct),
                'max_movement_pct': float(max_movement_pct),
                'movement_direction': movement_direction,
                'movement_pct': float(movement_pct),
                'is_anomaly': is_anomaly,
                'candles_count': int(len(relevant_candles)),

                # NEW: ¬´—á–∏—Å—Ç—ã–µ¬ª pre/post CAR –±–µ–∑ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)
                'pre_car_60m_pct': pre_car_60m_pct,
                'post_car_15m_pct': post_car_15m_pct,
                'post_car_60m_pct': post_car_60m_pct,
                'post_car_180m_pct': post_car_180m_pct,

                # NEW (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —à—É–º–∞)
                'pre_rv_60m': pre_rv_60m,
                'post_rv_60m': post_rv_60m,
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω—ã –¥–ª—è {symbol}: {e}")
            return None

    
    def analyze_news_impact(self, limit: int = None) -> List[Dict]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ü–µ–Ω—ã"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Ü–µ–Ω—ã...")
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ (—Å –ª–∏–º–∏—Ç–æ–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
        news_list = self.get_all_news_with_symbols(limit)
        if not news_list:
            logger.warning("–ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return []
        
        results = []
        
        for news in news_list:
            logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –Ω–æ–≤–æ—Å—Ç—å {news['news_id']}: {news['headline'][:50]}...")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –±—ã–ª –ª–∏ –æ—Ç–∫—Ä—ã—Ç —Ä—ã–Ω–æ–∫ –∏ —Ç–∏–ø —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
            market_open, session_type = self.get_market_session_info(news['created_at_utc'])
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤–µ—á–µ–π
            news_date = datetime.fromisoformat(news['created_at_utc'].replace('Z', '+00:00')).strftime('%Y-%m-%d')
            
            news_result = {
                'news_id': news['news_id'],
                'headline': news['headline'],
                'source': news['source'],
                'created_at_utc': news['created_at_utc'],
                'market_open': market_open,
                'session_type': session_type,
                'symbols_analysis': []
            }
            
            for symbol in news['symbols']:
                logger.info(f"  –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–∏–º–≤–æ–ª: {symbol}")
                
                # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞
                candles_df = self.get_candles_for_symbol_date(symbol, news_date)
                
                if candles_df is None or candles_df.empty:
                    logger.info(f"    –°–≤–µ—á–∏ –¥–ª—è {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                    continue
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
                price_analysis = self.find_price_changes(symbol, news['created_at_utc'], candles_df)
                
                if price_analysis:
                    symbol_result = {
                        'symbol': symbol,
                        'has_candles': True,
                        'price_analysis': price_analysis
                    }
                else:
                    symbol_result = {
                        'symbol': symbol,
                        'has_candles': True,
                        'price_analysis': None
                    }
                
                news_result['symbols_analysis'].append(symbol_result)
            
            results.append(news_result)
        
        return results
    
    def find_anomalies(self, results: List[Dict]) -> List[Dict]:
        """–ù–∞–π—Ç–∏ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (—Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º —Ü–µ–Ω—ã >= 1%)"""
        anomalies = []
        
        for news_result in results:
            for symbol_analysis in news_result['symbols_analysis']:
                if (symbol_analysis['has_candles'] and 
                    symbol_analysis['price_analysis'] and 
                    symbol_analysis['price_analysis']['is_anomaly']):
                    
                    anomaly = {
                        'news_id': news_result['news_id'],
                        'headline': news_result['headline'],
                        'symbol': symbol_analysis['symbol'],
                        'created_at_utc': news_result['created_at_utc'],
                        'market_open': news_result['market_open'],
                        'session_type': news_result.get('session_type', 'unknown'),
                        'max_movement_pct': symbol_analysis['price_analysis']['max_movement_pct'],
                        'movement_direction': symbol_analysis['price_analysis']['movement_direction'],
                        'movement_pct': symbol_analysis['price_analysis']['movement_pct'],
                        'price_at_news': symbol_analysis['price_analysis']['price_at_news'],
                        'max_high': symbol_analysis['price_analysis']['max_high'],
                        'min_low': symbol_analysis['price_analysis']['min_low']
                    }
                    anomalies.append(anomaly)
        
        return anomalies
    
    def save_results(self, results: List[Dict], output_file: str = "anomaly_analysis_results.json"):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def print_summary(self, results: List[Dict], anomalies: List[Dict]):
        """–í—ã–≤–µ—Å—Ç–∏ —Å–≤–æ–¥–∫—É –ø–æ –∞–Ω–∞–ª–∏–∑—É"""
        print("\n" + "="*80)
        print("–°–í–û–î–ö–ê –ê–ù–ê–õ–ò–ó–ê –ê–ù–û–ú–ê–õ–¨–ù–´–• –ù–û–í–û–°–¢–ï–ô")
        print("="*80)
        
        total_news = len(results)
        total_symbols = sum(len(news['symbols_analysis']) for news in results)
        symbols_with_candles = sum(
            sum(1 for sa in news['symbols_analysis'] if sa['has_candles'])
            for news in results
        )
        market_open_news = sum(1 for news in results if news['market_open'])
        total_anomalies = len(anomalies)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–µ—Å—Å–∏—è–º
        session_stats = {}
        for news in results:
            session = news.get('session_type', 'unknown')
            session_stats[session] = session_stats.get(session, 0) + 1
        
        print(f"–í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {total_news}")
        print(f"–í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {total_symbols}")
        print(f"–°–∏–º–≤–æ–ª–æ–≤ —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ —Å–≤–µ—á–∞–º–∏: {symbols_with_candles}")
        print(f"–ù–æ–≤–æ—Å—Ç–µ–π –≤–æ –≤—Ä–µ–º—è —Ç–æ—Ä–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏: {market_open_news}")
        print(f"–ù–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π (‚â•0.5%): {total_anomalies}")
        
        print(f"\n–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –¢–û–†–ì–û–í–´–ú –°–ï–°–°–ò–Ø–ú:")
        print("-" * 40)
        for session, count in sorted(session_stats.items()):
            session_name = {
                'pre_market': '–ü—Ä–µ-–º–∞—Ä–∫–µ—Ç (4:00-9:30 AM ET)',
                'regular_hours': '–†–µ–≥—É–ª—è—Ä–Ω—ã–µ —á–∞—Å—ã (9:30 AM-4:00 PM ET)',
                'after_hours': '–ü–æ—Å–ª–µ-–º–∞—Ä–∫–µ—Ç (4:00-8:00 PM ET)',
                'closed': '–†—ã–Ω–æ–∫ –∑–∞–∫—Ä—ã—Ç',
                'weekend': '–í—ã—Ö–æ–¥–Ω—ã–µ',
                'unknown': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            }.get(session, session)
            print(f"{session_name}: {count}")
        
        if anomalies:
            print(f"\n–¢–û–ü-10 –ê–ù–û–ú–ê–õ–¨–ù–´–• –î–í–ò–ñ–ï–ù–ò–ô:")
            print("-" * 80)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É –¥–≤–∏–∂–µ–Ω–∏—é —Ü–µ–Ω—ã
            sorted_anomalies = sorted(anomalies, key=lambda x: x['max_movement_pct'], reverse=True)
             
            for i, anomaly in enumerate(sorted_anomalies[:10], 1):
                 direction = "‚ÜóÔ∏è" if anomaly['movement_direction'] == "up" else "‚ÜòÔ∏è"
                 market_status = "üü¢ –†–´–ù–û–ö –û–¢–ö–†–´–¢" if anomaly['market_open'] else "üî¥ –†–´–ù–û–ö –ó–ê–ö–†–´–¢"
                 session_info = anomaly.get('session_type', 'unknown')
                 
                 # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                 news_time = datetime.fromisoformat(anomaly['created_at_utc'].replace('Z', '+00:00'))
                 formatted_time = news_time.strftime('%Y-%m-%d %H:%M:%S UTC')
                 
                 print(f"{i:2d}. {anomaly['symbol']:6s} {direction} {anomaly['max_movement_pct']:6.2f}% "
                       f"| {anomaly['headline'][:50]:50s} | {formatted_time} | {market_status} | {session_info}")
        
        print("="*80)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        finder = AnomalyNewsFinder()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        if not Path(finder.db_path).exists():
            logger.error(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {finder.db_path}")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ä—ã–Ω–∫–∞
        if not finder.market_data_path.exists():
            logger.error(f"–ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ä—ã–Ω–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {finder.market_data_path}")
            return
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ (–Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
        logger.info("–ó–∞–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        results = finder.analyze_news_impact(limit=1000)  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –Ω–æ–≤–æ—Å—Ç–µ–π
        
        if not results:
            logger.warning("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø—É—Å—Ç—ã")
            return
        
        # –ù–∞—Ö–æ–¥–∏–º –∞–Ω–æ–º–∞–ª–∏–∏
        anomalies = finder.find_anomalies(results)
        
        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        finder.print_summary(results, anomalies)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        finder.save_results(results)
        
        logger.info("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise


if __name__ == "__main__":
    main()
